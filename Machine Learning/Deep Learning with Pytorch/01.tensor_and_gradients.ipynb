{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a number, vector, matrix, or any n-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number\n",
    "t1 = torch.tensor(4)\n",
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "t3 = torch.tensor([[5., 6], \n",
    "                   [7 , 8], \n",
    "                   [9, 10]])\n",
    "print(t3)\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.]]])\n",
    "print(t4)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Operation And Gradient(Autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.tensor([[5., 6], \n",
    "                   [7 , 8]], requires_grad = True)\n",
    "t6 = torch.tensor([[10., 2], \n",
    "                   [3 , 8]],requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50., 12.],\n",
       "        [21., 64.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = t5 * t6\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: RuntimeError: grad can be implicitly created only for scalar outputs (and not vector(arrays))\n",
    "##### A tensor has to have a regular proper shape and each element should have the same datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()\n",
    "print('dres/dt5:', t5.grad)\n",
    "print('dres/dt6:', t6.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: x.grad means gradient of something with respect to x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor filled with the same value using fill function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69],\n",
       "        [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7 = torch.full((15,15) ,69)\n",
    "t7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty. -> using cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1.],\n",
       "        [0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t8 = torch.full((2,2),0.)\n",
    "t9 = torch.full((2,2),1.)\n",
    "\n",
    "# concatinating along the column\n",
    "comb = torch.cat((t8,t9))\n",
    "\n",
    "# concatinating along the row\n",
    "comb = torch.cat((t8,t9),1)\n",
    "comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TORCH.SPLIT \n",
    "\n",
    "Splits the tensor into chunks. Each chunk is a view of the original tensor.\n",
    "\n",
    "If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.\n",
    "\n",
    "If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(10).reshape(5,2)\n",
    "\n",
    "# with default split size:\n",
    "# a =torch.split(a, 4)\n",
    "\n",
    "# whit custom split size\n",
    "# a =torch.split(a, [1,4])\n",
    "# a\n",
    "\n",
    "# splitting along the column\n",
    "# a= torch.split(a,1,1)\n",
    "# a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy to Tensor & Tensor to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4.]])\n",
    "y = torch.tensor(x)\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.8415],\n",
       "        [ 0.9093,  0.1411],\n",
       "        [-0.7568, -0.9589],\n",
       "        [-0.2794,  0.6570],\n",
       "        [ 0.9894,  0.4121]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinFunc = torch.sin(a)\n",
    "sinFunc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b8dfd2a3c1f2992ce554b8d6072fa023a786c18868694f653695d06775e18da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
