{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality'] = data['quality'].astype(np.float32)\n",
    "x = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., ..., 6., 5., 6.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_target = np.array(x)\n",
    "quality_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
       "       ...,\n",
       "       [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],\n",
       "       [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],\n",
       "       [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = data.to_numpy()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_inputs = torch.from_numpy(inputs)\n",
    "tens_target = torch.from_numpy(quality_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7.4000e+00, 7.0000e-01, 0.0000e+00, 1.9000e+00, 7.6000e-02, 1.1000e+01,\n",
       "          3.4000e+01, 9.9780e-01, 3.5100e+00, 5.6000e-01, 9.4000e+00],\n",
       "         [7.8000e+00, 8.8000e-01, 0.0000e+00, 2.6000e+00, 9.8000e-02, 2.5000e+01,\n",
       "          6.7000e+01, 9.9680e-01, 3.2000e+00, 6.8000e-01, 9.8000e+00],\n",
       "         [7.8000e+00, 7.6000e-01, 4.0000e-02, 2.3000e+00, 9.2000e-02, 1.5000e+01,\n",
       "          5.4000e+01, 9.9700e-01, 3.2600e+00, 6.5000e-01, 9.8000e+00]],\n",
       "        dtype=torch.float64),\n",
       " tensor([5., 5., 5.]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(tens_inputs, tens_target)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2792, -0.0754, -0.0228,  ..., -0.2141,  0.0333,  0.0767],\n",
      "        [-0.2222, -0.0585,  0.2606,  ...,  0.1505, -0.2442, -0.1227],\n",
      "        [ 0.1504,  0.0412,  0.1379,  ...,  0.1883, -0.1683, -0.2968],\n",
      "        ...,\n",
      "        [ 0.0073, -0.2737,  0.1991,  ...,  0.1204,  0.0093, -0.2248],\n",
      "        [-0.0370, -0.1950, -0.1916,  ...,  0.2599,  0.1342, -0.0125],\n",
      "        [-0.2486,  0.0466,  0.2296,  ..., -0.2768,  0.1837, -0.0230]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2941, -0.0050, -0.1534,  ...,  0.0674,  0.2458, -0.0918],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(11,1599)\n",
    "w , b = model.parameters()\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarthak\\AppData\\Local\\Temp\\ipykernel_10816\\1929563904.py:2: UserWarning: Using a target size (torch.Size([1599])) that is different to the input size (torch.Size([1599, 1599])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = loss_fn(model(tens_inputs.float()), tens_target)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(142.7078, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(model(tens_inputs.float()), tens_target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sarthak\\Desktop\\coding\\Python_learn\\Machine Learning\\Deep Learning with Pytorch\\wine_quality_NN.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fit(\u001b[39m500\u001b[39;49m, model, loss_fn, opt,train_dl)\n",
      "\u001b[1;32mc:\\Users\\Sarthak\\Desktop\\coding\\Python_learn\\Machine Learning\\Deep Learning with Pytorch\\wine_quality_NN.ipynb Cell 15\u001b[0m in \u001b[0;36mfit\u001b[1;34m(num_epochs, model, loss_fn, opt, train_dl)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Train with batches of data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m xb,yb \u001b[39min\u001b[39;00m train_dl:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m# 1. Generate predictions\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(xb)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# 2. Calculate loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sarthak/Desktop/coding/Python_learn/Machine%20Learning/Deep%20Learning%20with%20Pytorch/wine_quality_NN.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         loss \u001b[39m=\u001b[39m loss_fn(pred, yb)\n",
      "File \u001b[1;32mc:\\Users\\Sarthak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Sarthak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "fit(500, model, loss_fn, opt,train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),\"weights_file_name_here.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b8dfd2a3c1f2992ce554b8d6072fa023a786c18868694f653695d06775e18da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
